{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMS_Spam_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBPopoDTnQrNgcNueMJO5c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ1Fw6e2ds_3",
        "outputId": "68a2d3b9-037d-4fd0-c6c6-ae6f15d6269e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Since I created this notebook in google colaboratory, I mounted my google drive to access the dataset.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDRBVKWXdz9-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/SMS_Spam_Dataset/spam.csv',encoding='Windows-1252', usecols=['v1','v2'])"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m63oIB4lfkrm",
        "outputId": "b1aa5703-a338-4c94-9300-d86fbd47f95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Get a count of each label to see if there is a bias towards one.\n",
        "print(\"Spam samples: \" + str(np.count_nonzero(data.values[:,0] == 'spam', axis=0)))\n",
        "print(\"Ham samples: \" + str(np.count_nonzero(data.values[:,0] == 'ham', axis=0)))"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam samples: 747\n",
            "Ham samples: 4825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QmCtB_mgN3V"
      },
      "source": [
        "# As seem above, the dataset provides far more ham examples than spam examples. This will result in our model being biased towards predicting ham.\n",
        "# To fix this, we will use only as many ham samples as there are spam samples.\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "count=0\n",
        "j=0\n",
        "while j<(len(data.values[:,0])):\n",
        "  if data.values[j,0] == 'spam':\n",
        "    y_data.append(1)\n",
        "    x_data.append(data.values[j,1])\n",
        "  if data.values[j,0] == 'ham':\n",
        "    if count<747:\n",
        "      y_data.append(0)\n",
        "      x_data.append(data.values[j,1])\n",
        "      count+=1\n",
        "  j+=1"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhBXNXexjlx_",
        "outputId": "1f69f043-d2d6-464e-8434-0de20b56de41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Confirm equal number of ham and spam samples\n",
        "print(y_data.count(0))\n",
        "print(y_data.count(1))"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "747\n",
            "747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyisHYTCjmhE",
        "outputId": "c72a2965-142c-4e2e-a347-e85ed0391b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#Below is code to gather a list of all unique words used throughout the samples.\n",
        "#This will allow us to convert each message into a one hot encoded vector.\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import words as allwords\n",
        "from string import punctuation\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "\n",
        "st=LancasterStemmer()\n",
        "customStopWords=set(stopwords.words('english')+list(punctuation)+[\"’\",\"”\",\"“\",\"\",\".\",\"..\",\"...\",\"``\",\"**\"])\n",
        "\n",
        "#Tokenize words in every message.\n",
        "words=[word_tokenize(i) for i in x_data]\n",
        "\n",
        "#Tokenization produced a list of tokenized words for each message, making a list of lists. This flattens the list.\n",
        "words=[item for sublist in words for item in sublist]\n",
        "\n",
        "#Remove all stopwords\n",
        "wordsWOStopwords=[word for word in words if word not in customStopWords]\n",
        "\n",
        "#Stem each word\n",
        "stemmedWords=[st.stem(word) for word in wordsWOStopwords]\n",
        "\n",
        "wordlist=list(set(stemmedWords))\n",
        "\n",
        "print(\"Number of unique words: \" + str(len(wordlist)))"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Number of unique words: 4173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgG3yTGw5ANl"
      },
      "source": [
        "#Convert messages into one hot encoded vectors using the list of words.\n",
        "X_data = []\n",
        "for j in range(len(x_data)):\n",
        "  Input=[]\n",
        "  for i in range(len(wordlist)):\n",
        "      Input.append(x_data[j].count(wordlist[i]))\n",
        "  X_data.append(np.array(Input))\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "Y_data = np.array(y_data)"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnNf7ojbf9-H"
      },
      "source": [
        "#Split the data into test and train data.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbsR1qP76PVt",
        "outputId": "bb75d1c9-6e4d-4c4b-a17c-5485052698c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#We now can define a simple neural network that takes the one hot encoded vector as input.\n",
        "#It has a single output, which will ideally be either 0 or 1 for our binary classification.\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = len(wordlist)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(128, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(16, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_126 (Dense)            (None, 128)               534272    \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 536,353\n",
            "Trainable params: 536,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI0s40SE8T3D",
        "outputId": "62a6fc84-bf10-40ca-d9bc-edbe2aed057c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "history = model.fit(X_train,y_train,epochs=7,verbose=True,batch_size=64)"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.8580\n",
            "Epoch 2/7\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9630\n",
            "Epoch 3/7\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9860\n",
            "Epoch 4/7\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1761 - accuracy: 0.9630\n",
            "Epoch 5/7\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9820\n",
            "Epoch 6/7\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9910\n",
            "Epoch 7/7\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP_QD_zzTOff"
      },
      "source": [
        "#Make a function that takes in a string message and predicts whether it is spam or not.\n",
        "def is_spam(message):\n",
        "  Input=[]\n",
        "  for i in range(len(wordlist)):\n",
        "    Input.append(message.count(wordlist[i]))\n",
        "  output=model.predict([Input])\n",
        "  if output>0.1: #Since the model does not output only 0 and 1, this threshold is used to determine what counts as a 1 and what counts as a 0.\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7Slp6lb7pM",
        "outputId": "1b2fc3c7-9498-4b5f-e9fb-15ddbc15c961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14739477634429932, 0.9655870199203491]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ3QGs9YWgX8",
        "outputId": "9fbf926f-7383-451e-a174-8cede4264ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_spam('We have detected fraudulent activity in your account. Please contact us for further information.')"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPopJLpcWm4U",
        "outputId": "d907e70f-7fc9-4988-b3aa-e156c5db5e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_spam('When do you think we could schedule a meeting?')"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5esWD9uyeU36",
        "outputId": "3ae0eefb-e87b-47f4-b184-f1d2d3c49948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_spam('Sorry for the late reply, when could we discuss the details further?')"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxlv2lrLeuPK",
        "outputId": "6de8c1c9-435f-4cca-b72f-9fb3aec211ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_spam('You have been selected to recieve a prize. You have 24 hours to claim it.')"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSRjpOqe6qx",
        "outputId": "efb52c8e-a93d-4507-9263-bcdcaf709709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_spam('Hey Richard, can we count on your vote in November?')"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    }
  ]
}